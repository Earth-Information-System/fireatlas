{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### DPS Coordinator\n",
    "\n",
    "This notebook interacts with the MAAP API. It submits and runs a single coordinating DPS dask job that manages jobs\n",
    "(see `fireatlas.FireRunDaskCoordinator.py`).\n",
    "\n",
    "The `poll_on_job_status` and `wait_for_job` allow us to block and get DPS job status for muliptle jobs before we continue on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!pip install -e .."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Tuple\n",
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from fireatlas.FireLog import logger\n",
    "\n",
    "\n",
    "from maap.maap import MAAP\n",
    "from maap.dps.dps_job import DPSJob\n",
    "from maap.utils import algorithm_utils\n",
    "\n",
    "\n",
    "class JobSubmissionException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_algorithm_config_filepath(dir_names):\n",
    "    current_file_dir = os.path.dirname(os.path.abspath(__name__))\n",
    "    return [\n",
    "        os.path.join(current_file_dir, f'{dir_name}', 'algorithm_config.yaml')\n",
    "        for dir_name in dir_names\n",
    "    ]\n",
    "\n",
    "\n",
    "def validate_job_submission(submitted_jobs: Tuple[DPSJob]) -> Tuple[DPSJob]:\n",
    "    \"\"\"we don't retry job submissions, they should ideally always work\n",
    "\n",
    "    validate status of job submission results and return result 'job_id'\n",
    "    \"\"\"\n",
    "    failed_statuses = [result for result in submitted_jobs if result.status == 'failed']\n",
    "    if any(failed_statuses):\n",
    "        raise JobSubmissionException(f\"[ SUBMISSION FAILED ]: the following jobs failed to submit {failed_statuses}\")\n",
    "    return submitted_jobs\n",
    "\n",
    "\n",
    "def wait_for_job(dps_job: DPSJob) -> DPSJob:\n",
    "    \"\"\"this internal DPSJob function will block until job completes and use exponential backoff\n",
    "    https://github.com/MAAP-Project/maap-py/blob/master/maap/dps/dps_job.py#L80C9-L80C28\n",
    "\n",
    "    it seems the statuses.lower() are: ['failed', 'succeeded', 'accepted', 'running']\n",
    "    https://github.com/MAAP-Project/maap-py/blob/master/maap/dps/dps_job.py\n",
    "    \"\"\"\n",
    "    return dps_job.wait_for_completion()\n",
    "\n",
    "\n",
    "def poll_on_job_status(jobs: Tuple[DPSJob]) -> Tuple[DPSJob]:\n",
    "    failed_jobs = []\n",
    "    # don't want to overwhelm the MAAP api so keeping max_workers relatively small\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        dps_job_futures = [executor.submit(wait_for_job, dps_job) for dps_job in jobs]\n",
    "        for dps_job in concurrent.futures.as_completed(dps_job_futures):\n",
    "            try:\n",
    "                if dps_job.result().retrieve_status().lower() != 'succeeded':\n",
    "                    failed_jobs.append(dps_job)\n",
    "            except Exception as e:\n",
    "                logger.exception(f\"'poll_on_jobs_status' failed with {e}\")\n",
    "    return failed_jobs\n",
    "\n",
    "\n",
    "def track_submitted_jobs(submitted_jobs: Tuple[DPSJob]) -> Tuple[DPSJob]:\n",
    "    queued_jobs = validate_job_submission(submitted_jobs)\n",
    "    failed_jobs = poll_on_job_status(queued_jobs)\n",
    "    return failed_jobs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dask Coodinator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tst = [2023,1,1,'AM']\n",
    "ted = [2023,7,1,'PM']\n",
    "region = [\"Oregon\", [-124.925537,41.672912,-115.565186,46.513516]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "configs = get_algorithm_config_filepath(['coordinator',])\n",
    "maap_api = MAAP(maap_host='api.maap-project.org')\n",
    "algo_config = algorithm_utils.read_yaml_file(configs[0])\n",
    "algo_config.pop('inputs')\n",
    "print(algo_config)\n",
    "\n",
    "submitted_jobs = []\n",
    "submit_job_kwargs = {\n",
    "    \"identifier\": f\"job-{algo_config['algorithm_name']}:{algo_config['algorithm_version']}\",\n",
    "    \"algo_id\": algo_config[\"algorithm_name\"],\n",
    "    \"version\": algo_config[\"algorithm_version\"],\n",
    "    \"username\": \"gcorradini\",\n",
    "    \"queue\": algo_config[\"queue\"],\n",
    "}\n",
    "param_kwargs = {\"regnm\": region[0], \"tst\":  json.dumps(tst), \n",
    "                \"bbox\": region[1], \"ted\": json.dumps(ted), \"operation\": \"--coordinate-all\"}\n",
    "\n",
    "result = maap_api.submitJob(**submit_job_kwargs, **param_kwargs)\n",
    "submitted_jobs.append(result)\n",
    "queued_jobs = validate_job_submission(submitted_jobs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "failed_jobs = poll_on_job_status(queued_jobs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "failed_jobs[0].result().retrieve_result()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo",
   "language": "python",
   "name": "pangeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}